{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GXbipFnl7n3"
   },
   "source": [
    "# Here this crawler will extract names of all the universities from a webpage and save the them into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAxz5XtlGiJD"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-22538ccd0d4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlwmd5UqeklI"
   },
   "source": [
    "## **This is a crawler function which reads date from the website given below. The website has the names of most of the universities in the world and we are trying to read that and write all that into a csv file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bub0NBauiPJI"
   },
   "source": [
    "link: https://www.4icu.org/reviews/index2.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKC9Q8mmeTk-"
   },
   "outputs": [],
   "source": [
    "def crawler_function():\n",
    "    maxpage=27\n",
    "    names=[]\n",
    "    \n",
    "    #using this for loop it iterates over all the pages \n",
    "    #present on the website.\n",
    "    for page in range(2,maxpage+1,1):\n",
    "        \n",
    "        #here a new link is generated for all the pages on website\n",
    "        url=\"https://www.4icu.org/reviews/index\"+str(page)+\".htm\"\n",
    "        \n",
    "        \n",
    "        #request to get the web page\n",
    "        source_code=requests.get(url)\n",
    "        \n",
    "        #convert source code of web page into text\n",
    "        plain_text=source_code.text\n",
    "        \n",
    "        \n",
    "        soup=BeautifulSoup(plain_text)\n",
    "        x=0\n",
    "        \n",
    "        \n",
    "        #loop below basically extracts the \n",
    "        #lines having the name of universities\n",
    "        for link in soup.findAll('a',):#{ 'href'  }):\n",
    "            l=str(link)\n",
    "            x=re.search(\"s/[1-9]+.htm\",l)\n",
    "            if(x):\n",
    "                names.append(l)        \n",
    "                \n",
    "                \n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DETffqjmf7hO"
   },
   "source": [
    "## This names variable has a list of names of all the Universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfV8DDJELHdF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-abc16c40c3c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrawler_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-cc004f9c4a07>\u001b[0m in \u001b[0;36mcrawler_function\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#request to get the web page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0msource_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m#convert source code of web page into text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "names=crawler_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "qU7830nagdVT",
    "outputId": "f47f95c7-468f-45f9-cdb9-c59b39b04e1a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e9faf7881b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "names[1:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PZzMYKLKgRaP"
   },
   "source": [
    "# Now we will do pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgqqacCxgPQQ"
   },
   "outputs": [],
   "source": [
    "#remove the uses less parts using re library\n",
    "def pre_processing(names):\n",
    "    for i in range(len(names)):\n",
    "        l=names[i]\n",
    "        l=re.sub(\"</a>\",\"\",l,1)\n",
    "        pos=re.search(\">\",l).start()+1\n",
    "        l=l[pos:-1].strip()\n",
    "        names[i]=l\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h6o2KPOQhfWh"
   },
   "outputs": [],
   "source": [
    "names=pre_processing(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "AdUHTsfLg-Hc",
    "outputId": "d2f84966-ad84-4d0c-a1d9-f5f78ff990fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abbottabad University of Science and Technolog',\n",
       " 'Abdul Wali Khan University Marda',\n",
       " 'Abdullah Gül Üniversites',\n",
       " 'Abdulrahman Al-Sumait Memorial Universit',\n",
       " 'Abertay Universit',\n",
       " 'Aberystwyth Universit',\n",
       " 'Abhilashi Universit',\n",
       " 'Abilene Christian Universit',\n",
       " 'Abourihan Higher Education Institut',\n",
       " 'Abra State Institute of Science and Technolog',\n",
       " 'Abraham Baldwin Agricultural Colleg',\n",
       " 'Abu Ali ibn Sino nomidagi Buxoro Davlat Tibbiyot Institut',\n",
       " 'Abu Dhabi Polytechni',\n",
       " 'Abu Dhabi Universit',\n",
       " 'Abubakar Tafawa Balewa Universit',\n",
       " 'Academia de Muzica Gheorghe Dim',\n",
       " 'Academia de Muzica, Teatru si Arte Plastic',\n",
       " 'Academia de Studii Economice din Moldov',\n",
       " 'Academia Nacional Superior de Orquestr']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0EXUnbjQlMoY",
    "outputId": "f9d8d04f-dc0a-438d-9b4b-6587c1ec158f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0b72be7b249c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "names[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Me3e3xikF_nd",
    "outputId": "be8a31d9-2990-403c-8ac4-270171c03b99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9568"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names) #total number of all the universities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MidTkVTlhsi9"
   },
   "source": [
    "# Here we write all the names present in this \"names[ ]\" into a csv file. \n",
    "# Open the csv file generate in excel. it is saved in same location as this file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kvVoF-Y9N3-n"
   },
   "outputs": [],
   "source": [
    "#convert list into pandas dataframe and save into a csv file.\n",
    "df=pd.DataFrame(names)\n",
    "df.to_csv(\"Names_of_all_the_universities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yudrI0vU8iiz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "crawler_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
